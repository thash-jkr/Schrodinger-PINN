input layer = 2
hidden layers = [512, 512, 512, 512, 512, 512]
output layer = 2

optimizer:
`
optimizer = torch.optim.Adam(
    model.parameters(),
    lr=0.001,
    betas=(0.9, 0.999)
)

decay_rate = 0.9
steps = 2000

def exp_decay(step):
    return decay_rate ** (step / steps)

scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=exp_decay)
`

